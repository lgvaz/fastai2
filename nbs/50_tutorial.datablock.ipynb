{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastai2.data.all import *\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data block tutorial\n",
    "\n",
    "> Using the data block accross all applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll see how to use the data block API on a variety of tasks and how to debug data blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin with examples of image classification problems. There are two kinds of image classification problems: problems with single-label (each image as one given label) or multi-label (each image can have multiple or no labels at all). We will cover those two kinds here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST (single label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[MNIST](http://yann.lecun.com/exdb/mnist/) is a dataset of hand-written digits from 0 to 9. We can very easily load it in the data block API by answering the following questions:\n",
    "\n",
    "- what are the types of our inputs and targets? Black and white images and labels.\n",
    "- where is the data? In subfolders.\n",
    "- how do we know if a sample is in the training or the validation set? By looking at the grandparent folder.\n",
    "- how do we know the label of an image? By looking at the parent folder.\n",
    "\n",
    "In terms of the API, those answers translate like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = DataBlock(blocks=(ImageBlock(cls=PILImageBW), CategoryBlock), \n",
    "                  get_items=get_image_files, \n",
    "                  splitter=GrandparentSplitter(),\n",
    "                  get_y=parent_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our types become blocks: one for images (using the black and white `PILImageBW` class) and one for categories. Searching subfolder for all image filenames is done by the `get_image_files` function. The split training/validation is done by using a `GrandparentSplitter`. And the function to get our targets (often called `y`) is `parent_label`.\n",
    "\n",
    "In itself, a data block is just a blueprint. It does not do anything and does not check for errors. You have to feed it the source of the data to actually gather something. This is done with the `.dataloaders` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = mnist.dataloaders(untar_data(URLs.MNIST_TINY))\n",
    "dls.show_batch(max_n=9, figsize=(4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If something went wrong in the previous step, or if you're just curious about what happened under the hood, use the `summary` method. It will go verbosely step by step, and you will see at which point the process failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting-up type transforms pipelines\n",
      "Collecting items from /home/lgvaz/.fastai/data/mnist_tiny\n",
      "Found 1420 items\n",
      "2 datasets of sizes 709,691\n",
      "Setting up Pipeline: PILBase.create\n",
      "Setting up Pipeline: parent_label -> Categorize\n",
      "\n",
      "Building one sample\n",
      "  Pipeline: PILBase.create\n",
      "    starting from\n",
      "      /home/lgvaz/.fastai/data/mnist_tiny/train/7/730.png\n",
      "    applying PILBase.create gives\n",
      "      PILImageBW mode=L size=28x28\n",
      "  Pipeline: parent_label -> Categorize\n",
      "    starting from\n",
      "      /home/lgvaz/.fastai/data/mnist_tiny/train/7/730.png\n",
      "    applying parent_label gives\n",
      "      7\n",
      "    applying Categorize gives\n",
      "      TensorCategory(1)\n",
      "\n",
      "Final sample: (PILImageBW mode=L size=28x28, TensorCategory(1))\n",
      "\n",
      "\n",
      "Setting up after_item: Pipeline: ToTensor\n",
      "Setting up before_batch: Pipeline: \n",
      "Setting up after_batch: Pipeline: IntToFloatTensor\n",
      "\n",
      "Building one batch\n",
      "Applying item_tfms to the first sample:\n",
      "  Pipeline: ToTensor\n",
      "    starting from\n",
      "      (PILImageBW mode=L size=28x28, TensorCategory(1))\n",
      "    applying ToTensor gives\n",
      "      (TensorImageBW of size 1x28x28, TensorCategory(1))\n",
      "\n",
      "Adding the next 3 samples\n",
      "\n",
      "No before_batch transform to apply\n",
      "\n",
      "Collating items in a batch\n",
      "\n",
      "Applying batch_tfms to the batch built\n",
      "  Pipeline: IntToFloatTensor\n",
      "    starting from\n",
      "      (TensorImageBW of size 4x1x28x28, TensorCategory([1, 1, 1, 1], device='cuda:0'))\n",
      "    applying IntToFloatTensor gives\n",
      "      (TensorImageBW of size 4x1x28x28, TensorCategory([1, 1, 1, 1], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "mnist.summary(untar_data(URLs.MNIST_TINY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go over another example!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pets (single label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Oxford IIIT Pets dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/) is a dataset of pictures of dogs and cats, with 37 different breeds. A slight (but very) important difference with MNIST is that images are now not all of the same size. In MNIST they were all 28 by 28 pixels, but here they have different aspect ratios or dimensions. Therefore, we will need to add something to make them all the same size to be able to assemble them together in a batch. We will also see how to add data augmentation.\n",
    "\n",
    "So let's go over the same questions as before and add two more:\n",
    "\n",
    "- what are the types of our inputs and targets? Images and labels.\n",
    "- where is the data? In subfolders.\n",
    "- how do we know if a sample is in the training or the validation set? We'll take a random split.\n",
    "- how do we know the label of an image? By looking at the parent folder.\n",
    "- do we want to apply a function to a given sample? Yes, we need to resize everything to a given size.\n",
    "- do we want to apply a function to a batch after it's created? Yes, we want data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "get_y contains 2 functions, but must contain 1 (one for each target)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3b86cd6625de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                  \u001b[0mget_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattrgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRegexLabeller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'^(.*)_\\d+.jpg$'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                  \u001b[0mitem_tfms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                  batch_tfms=aug_transforms())\n\u001b[0m",
      "\u001b[0;32m~/libs/fastcore/fastcore/foundation.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMethodType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMethodType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__func__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mold_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m     \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_methods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/fastai2/fastai2/data/block.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, blocks, dl_type, getters, n_inp, item_tfms, batch_tfms, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mn_targs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetters\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_inp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_targs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'get_y contains {len(L(self.get_y))} functions, but must contain {n_targs} (one for each target)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_inp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_inp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_inp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: get_y contains 2 functions, but must contain 1 (one for each target)"
     ]
    }
   ],
   "source": [
    "pets = DataBlock(blocks=(ImageBlock, CategoryBlock), \n",
    "                 get_items=get_image_files, \n",
    "                 splitter=RandomSplitter(),\n",
    "                 get_y=[attrgetter(\"name\"), RegexLabeller(pat = r'^(.*)_\\d+.jpg$')],\n",
    "                 item_tfms=Resize(128),\n",
    "                 batch_tfms=aug_transforms())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And like for MNIST, we can see how the answers to those questions directly translate in the API. Our types become blocks: one for images and one for categories. Searching subfolder for all image filenames is done by the `get_image_files` function. The split training/validation is done by using a `RandomSplitter`. The function to get our targets (often called `y`) is `parent_label`. We apply a resize at the item level and `aug_transforms()` at the batch level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = pets.dataloaders(untar_data(URLs.PETS)/\"images\")\n",
    "dls.show_batch(max_n=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how we can use the same API for a multi-label problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pascal (multi-label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Pascal dataset](http://host.robots.ox.ac.uk/pascal/VOC/) is originally an object detection dataset (we have to predict where some objects are in pictures). But it contains lots of pictures with various objects in them, so it gives a great example for a multi-label problem. Let's download it and have a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pascal_source = untar_data(URLs.PASCAL_2007)\n",
    "df = pd.read_csv(pascal_source/\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pascal = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n",
    "                   get_x=ColReader(0, pref=pascal_source/\"train\"),\n",
    "                   splitter=ColSplitter(),\n",
    "                   get_y=ColReader(1, label_delim=' '),\n",
    "                   item_tfms=Resize(224),\n",
    "                   batch_tfms=aug_transforms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = pascal.dataloaders(df)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pascal = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n",
    "                   get_x=lambda x:pascal_source/\"train\"/f'{x[0]}',\n",
    "                   splitter=ColSplitter(),\n",
    "                   get_y=lambda x:x[1].split(' '),\n",
    "                   item_tfms=Resize(224),\n",
    "                   batch_tfms=aug_transforms())\n",
    "\n",
    "dls = pascal.dataloaders(df)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pascal_items(x): return (\n",
    "    f'{pascal_source}/train/'+x.fname, x.labels.str.split())\n",
    "\n",
    "pascal = DataBlock.from_columns(blocks=(ImageBlock, MultiCategoryBlock),\n",
    "                   get_items=_pascal_items,\n",
    "                   splitter=RandomSplitter(),\n",
    "                   item_tfms=Resize(224),\n",
    "                   batch_tfms=aug_transforms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = pascal.dataloaders(df)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pascal = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n",
    "                   get_x=lambda o:f'{pascal_source}/train/'+o.fname,\n",
    "                   get_y=lambda o:o.labels.split(),\n",
    "                   splitter=ColSplitter(),\n",
    "                   item_tfms=Resize(224),\n",
    "                   batch_tfms=aug_transforms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = pascal.dataloaders(df)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image localization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camvid = DataBlock(blocks=(ImageBlock, ImageBlock(cls=PILMask)),\n",
    "    get_items=get_image_files,\n",
    "    splitter=RandomSplitter(),\n",
    "    get_y=lambda o: untar_data(URLs.CAMVID_TINY)/'labels'/f'{o.stem}_P{o.suffix}',\n",
    "    batch_tfms=aug_transforms())\n",
    "\n",
    "dls = camvid.dataloaders(untar_data(URLs.CAMVID_TINY)/\"images\")\n",
    "dls.show_batch(max_n=9, vmin=1, vmax=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biwi_source = untar_data(URLs.BIWI_SAMPLE)\n",
    "fn2ctr = (biwi_source/'centers.pkl').load()\n",
    "\n",
    "biwi = DataBlock(blocks=(ImageBlock, PointBlock),\n",
    "                 get_items=get_image_files,\n",
    "                 splitter=RandomSplitter(),\n",
    "                 get_y=lambda o:fn2ctr[o.name].flip(0),\n",
    "                 batch_tfms=aug_transforms())\n",
    "\n",
    "dls = biwi.dataloaders(biwi_source)\n",
    "dls.show_batch(max_n=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_source = untar_data(URLs.COCO_TINY)\n",
    "images, lbl_bbox = get_annotations(coco_source/'train.json')\n",
    "img2bbox = dict(zip(images, lbl_bbox))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = DataBlock(blocks=(ImageBlock, BBoxBlock, BBoxLblBlock),\n",
    "                 get_items=get_image_files,\n",
    "                 splitter=RandomSplitter(),\n",
    "                 getters=[noop, lambda o: img2bbox[o.name][0], lambda o: img2bbox[o.name][1]], \n",
    "                 item_tfms=Resize(128),\n",
    "                 batch_tfms=aug_transforms(),\n",
    "                 n_inp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = coco.dataloaders(coco_source)\n",
    "dls.show_batch(max_n=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "df = pd.read_csv(path/'texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_lm = DataBlock(blocks=(TextBlock.from_df('text', is_lm=True),),\n",
    "                    get_x=attrgetter('text'),\n",
    "                    splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = imdb_lm.dataloaders(df, bs=64, seq_len=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch(max_n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_clas = DataBlock(blocks=(TextBlock.from_df('text'), CategoryBlock),\n",
    "                      get_x=attrgetter('text'),\n",
    "                      get_y=attrgetter('label'),\n",
    "                      splitter=RandomSplitter())\n",
    "\n",
    "dls = imdb_clas.dataloaders(df, bs=64, seq_len=72)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular data TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.tabular.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_source = untar_data(URLs.ADULT_SAMPLE)\n",
    "df = pd.read_csv(adult_source/'adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "cont_names = ['age', 'fnlwgt', 'education-num']\n",
    "procs = [Categorify, FillMissing, Normalize]\n",
    "splits = RandomSplitter()(range_of(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = TabularPandas(df, procs, cat_names, cont_names, y_names=\"salary\", splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = to.dataloaders()\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
